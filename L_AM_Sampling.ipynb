{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Adaptive* MH using *Cholesky decomposition* of the covariance\n",
    "\n",
    "See the 1999 and 2001 papers of Haario et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "import random\n",
    "import numba\n",
    "from collections import namedtuple\n",
    "%precision 4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from importlib import reload \n",
    "reload(ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MH_Sampling import acceptance_decision\n",
    "from FileHandling import save_state\n",
    "from TestSuite import generate_state_space, generate_iid_samples, get_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AM_Pars = namedtuple('AM_Pars', \n",
    "                     ['Origin', 'Id',\n",
    "                      'sigma_0', 'sigma_opt', 'L_0', \n",
    "                      'z_samples'])\n",
    "\n",
    "def init_AM_pars(sp):\n",
    "    dim, origin, idty = sp['dim'], sp['Origin'], sp['Id'] \n",
    "    sigma_0, sigma_opt = 0.1/np.sqrt(dim), sp['sigma_opt']\n",
    "    L_0 = idty\n",
    "    return AM_Pars(Origin=origin, Id=idty,\n",
    "                   sigma_0=sigma_0, sigma_opt=sigma_opt, L_0=L_0,\n",
    "                   z_samples=get_standard_normal_samples(sp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive MH algorithm *AM*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the candidate next sample\n",
    "\n",
    "We consider a version of the *Adaptive Metropolis* (*AM*) sampler of Haario\n",
    "et al. (2001). We want to sample from the $d$-dimensional target distribution $\\pi(\\mathbf{x})$. \n",
    "\n",
    "We perform a Metropolis algorithm with covariance matrix $\\pmb{Q}_n$ at iteration $n$ given by\n",
    "\n",
    "$$\\mathbf{Q}_n(\\mathbf{x}, ·) = N(\\mathbf{x}, \\sigma_{0}^2 \\mathbb{1}_d)$$\n",
    "\n",
    "for $n \\leq 2d$, while for $n > 2d$\n",
    "\n",
    "$$\\mathbf{Q}_n(\\mathbf{x}, ·) = (1 − \\beta) N(\\mathbf{x}, \\sigma_{opt}^2 \\mathbf{C}_n) + \n",
    "\\beta N(\\mathbf{x}, \\sigma_{0}^2 \\mathbb{1}_d)$$\n",
    "\n",
    "where $\\mathbf{C}_n$ is the current empirical estimate of the covariance of the target distribution\n",
    "based on the samples so far, $\\sigma_{0}^2 = \\frac{0.1^2}{d}$ and $\\sigma_{opt}^2 = \\frac{2.38^2}{d}$ are the initial and optimal scale, respectively, and $\\beta$ is a small positive constant, we use $\\beta = 0.05$.\n",
    " \n",
    "In other words, the next candidate is sampled from\n",
    "\n",
    "$$\\mathbf{x}^{*} \\sim \\mathbf{Q}_n(\\mathbf{x}, ·)$$\n",
    " \n",
    "The text above is adapted from Section 2 of Gareth O. Roberts and Jeffrey S. Rosenthal (2008) \n",
    "*Examples of Adaptive MCMC*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random covariance matrix $M$ from the above paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Factors = namedtuple('Factors',\n",
    "                     ['Chol', 'Scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prop_data(L, n, pars):\n",
    "    beta = 0.05\n",
    "    d, _ = L.shape\n",
    "    sigma_0, sigma_opt, L_0 = pars.sigma_0, pars.sigma_opt, pars.L_0\n",
    "    init, current = Factors(Chol=L_0, Scale=sigma_0), Factors(Chol=L, Scale=sigma_opt)\n",
    "    init_period = 2*d\n",
    "    if n <= init_period:\n",
    "        return init\n",
    "    else:\n",
    "        return current if np.random.binomial(n=1, p=1-beta) else init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of candidate\n",
    "\n",
    "If the proposal distribution is the $d$-dimensional multivariate normal distribution $N(\\pmb{m}, \\pmb{C})$ then \n",
    "the next candidate $\\pmb{x}^{*}$ is generated according to that distribution, i.e. \n",
    "\n",
    "$$\\pmb{x}^{*} \\sim N(\\pmb{m}, \\pmb{C})$$\n",
    "\n",
    "If $L$ is the lower Cholesky factor of $C$, i.e. $C = L L^\\top$ this can be rewritten as \n",
    "\n",
    "$$\\pmb{x}^{*} = \\pmb{m} + L \\pmb{z}$$\n",
    "\n",
    "where $\\pmb{z} \\sim N(\\pmb{0}, \\mathbb{1}_d)$ is a sample of the $d$-dimensional standard normal distribution. \n",
    "\n",
    "In case of $$\\pmb{x}^{*} \\sim N(\\pmb{m}, \\sigma^2 \\pmb{C})$$ this becomes\n",
    "\n",
    "$$\\pmb{x}^{*} = \\pmb{m} + \\sigma L \\pmb{z}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def C_generate_candidate(m, C, s):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_generate_candidate(m, L, s, z):\n",
    "    return m + s*L@z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see \"A More Efficient Rank-one Covariance Matrix Update for Evolution Strategies\" Igel, Krause 2015\n",
    "# and adapted slightly to incoporate alpha, beta != 1\n",
    "@numba.jit(nopython=True)\n",
    "def rank_1_update(L, u, alpha, beta):\n",
    "    assert alpha > 0, 'Argument alpha should be positive'\n",
    "    assert beta > 0, 'Argument beta should be positive'\n",
    "    d = len(u)\n",
    "    L = np.sqrt(alpha)*L  #Added\n",
    "    b = 1\n",
    "    nL = np.zeros_like(L)\n",
    "    v = np.copy(u)  #Added\n",
    "    for j in np.arange(d):\n",
    "        nL[j,j] = np.sqrt(L[j,j]**2 + (beta/b)*(v[j]**2))\n",
    "        gamma = b*L[j,j]**2 + beta*v[j]**2\n",
    "        for k in range(j+1, d):\n",
    "            v[k] = v[k] - (v[j]/L[j,j])*L[k,j]\n",
    "            nL[k,j] = (nL[j,j]/L[j,j])*L[k,j] + (nL[j,j]*beta*v[j]/gamma)*v[k]\n",
    "        b = b + beta*(v[j]**2/L[j,j]**2)\n",
    "    return nL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_moments(mean, L, sample, n):\n",
    "    next_n = n + 1\n",
    "    w = 1/next_n\n",
    "    new_mean = mean + w*(sample - mean)\n",
    "    new_L = rank_1_update(L=L, u=sample, alpha=1-w, beta=w)\n",
    "    return new_mean, new_L, next_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def update_L(samples):\n",
    "    N, d = samples.shape\n",
    "    initial_period = 2*d\n",
    "    initial_cov = np.cov(samples[:initial_period], rowvar=False)\n",
    "    initial_mean = np.mean(samples[:initial_period], axis=0)\n",
    "    C = initial_cov\n",
    "    L = la.cholesky(initial_cov) \n",
    "    mean = initial_mean\n",
    "    for n in range(initial_period, len(samples)):\n",
    "        sample = samples[n]\n",
    "        w = 1/(n+1)\n",
    "        L = rank_1_update(L, sample-mean, alpha=(n-1)/n, beta=w)\n",
    "        mean = (1-w)*mean + w*sample\n",
    "    return L@L.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AM_sampler(pars, target, initial_state, run_data): \n",
    "    ds, N = run_data.DataStore, run_data.N\n",
    "    \n",
    "    \n",
    "    target_pdf = target['pdf']\n",
    "    z_samples = pars.z_samples\n",
    "    \n",
    "    current = initial_state\n",
    "    mean, L, sigma_0 = pars.Origin, pars.L_0, pars.sigma_0\n",
    "    accepted = True\n",
    "    d = len(initial_state)\n",
    "    init_period = 2*d\n",
    "    samples=[]\n",
    "    for n in range(init_period):\n",
    "        save_state(data_store=ds, step=n,\n",
    "                   state=current, value=target_pdf(current),\n",
    "                   mean=mean, covariance=L, accepted_p=accepted)\n",
    "        candidate = L_generate_candidate(m=current, L=L, s=sigma_0, z=z_samples[n])\n",
    "        accepted = MH_decision(current=current, proposed=candidate, pdf=target_pdf)\n",
    "        if accepted: \n",
    "            current = candidate\n",
    "        else:\n",
    "            current = current\n",
    "        samples.append(current)\n",
    "    # Calculate the first two moments at the end of initial period.\n",
    "    initial_cov = np.cov(samples, rowvar=False)\n",
    "    initial_mean = np.mean(samples, axis=0)\n",
    "    C = initial_cov\n",
    "    L = la.cholesky(initial_cov) \n",
    "    mean = initial_mean\n",
    "    \n",
    "   \n",
    "    # Once the initial period is finished we start to adapt.\n",
    "    for n in range(init_period, N):\n",
    "        #if n%1000 == 0:\n",
    "        #    print('n:', n)\n",
    "        save_state(data_store=ds, step=n,\n",
    "                   state=current, value=target_pdf(current),\n",
    "                   mean=mean, covariance=L, accepted_p=accepted)\n",
    "        \n",
    "        p_L, p_sigma = get_prop_data(L=L, n=n, pars=pars)\n",
    "        candidate = L_generate_candidate(m=current, L=p_L, s=p_sigma, z=z_samples[n])\n",
    "        accepted = MH_decision(current=current, proposed=candidate, pdf=target_pdf)\n",
    "        if accepted: \n",
    "            current = candidate\n",
    "        mean, L, n = update_moments(mean, L, current, n)\n",
    "    return run_data"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
